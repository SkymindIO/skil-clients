=begin
#Endpoints

#Endpoints API for different services in SKIL

OpenAPI spec version: 1.2.0-beta

Generated by: https://github.com/swagger-api/swagger-codegen.git
Swagger Codegen version: 2.4.0-SNAPSHOT

=end

require 'uri'

module SkilCient
  class InferenceApi
    attr_accessor :api_client

    def initialize(api_client = ApiClient.default)
      @api_client = api_client
    end
    # Use the deployed model to classify the input
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [ClassificationResult]
    def classify(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = classify_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Use the deployed model to classify the input
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(ClassificationResult, Fixnum, Hash)>] ClassificationResult data, response status code and response headers
    def classify_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.classify ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.classify"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.classify"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.classify"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.classify"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/classify'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'ClassificationResult')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#classify\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Same as /classify but returns the output as Base64NDArrayBody
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Base64NDArrayBody]
    def classifyarray(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = classifyarray_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Same as /classify but returns the output as Base64NDArrayBody
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(Base64NDArrayBody, Fixnum, Hash)>] Base64NDArrayBody data, response status code and response headers
    def classifyarray_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.classifyarray ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.classifyarray"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.classifyarray"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.classifyarray"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.classifyarray"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/classifyarray'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'Base64NDArrayBody')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#classifyarray\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Use the deployed model to classify the input, using input image file from multipart form data.
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :image The file to upload.
    # @return [ClassificationResult]
    def classifyimage(deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = classifyimage_with_http_info(deployment_name, version_name, model_name, opts)
      data
    end

    # Use the deployed model to classify the input, using input image file from multipart form data.
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :image The file to upload.
    # @return [Array<(ClassificationResult, Fixnum, Hash)>] ClassificationResult data, response status code and response headers
    def classifyimage_with_http_info(deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.classifyimage ...'
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.classifyimage"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.classifyimage"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.classifyimage"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/classifyimage'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['image'] = opts[:'image'] if !opts[:'image'].nil?

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'ClassificationResult')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#classifyimage\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Detect the objects, given a (input) prediction request
    # @param id the GUID for mapping the results in the detections
    # @param needs_preprocessing (true) if the image needs preprocessing
    # @param threshold A threshold, indicating the required surety for detecting a bounding box. For example, a threshold of 0.1 might give thousand bounding boxes for an image and a threshold of 0.99 might give none.
    # @param file the image file to detect objects from
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [DetectionResult]
    def detectobjects(id, needs_preprocessing, threshold, file, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = detectobjects_with_http_info(id, needs_preprocessing, threshold, file, deployment_name, version_name, model_name, opts)
      data
    end

    # Detect the objects, given a (input) prediction request
    # @param id the GUID for mapping the results in the detections
    # @param needs_preprocessing (true) if the image needs preprocessing
    # @param threshold A threshold, indicating the required surety for detecting a bounding box. For example, a threshold of 0.1 might give thousand bounding boxes for an image and a threshold of 0.99 might give none.
    # @param file the image file to detect objects from
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(DetectionResult, Fixnum, Hash)>] DetectionResult data, response status code and response headers
    def detectobjects_with_http_info(id, needs_preprocessing, threshold, file, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.detectobjects ...'
      end
      # verify the required parameter 'id' is set
      if @api_client.config.client_side_validation && id.nil?
        fail ArgumentError, "Missing the required parameter 'id' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'needs_preprocessing' is set
      if @api_client.config.client_side_validation && needs_preprocessing.nil?
        fail ArgumentError, "Missing the required parameter 'needs_preprocessing' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'threshold' is set
      if @api_client.config.client_side_validation && threshold.nil?
        fail ArgumentError, "Missing the required parameter 'threshold' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'file' is set
      if @api_client.config.client_side_validation && file.nil?
        fail ArgumentError, "Missing the required parameter 'file' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.detectobjects"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.detectobjects"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/detectobjects'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['id'] = id
      form_params['needsPreprocessing'] = needs_preprocessing
      form_params['threshold'] = threshold
      form_params['file'] = file

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'DetectionResult')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#detectobjects\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Run inference on the input and returns it as a JsonArrayResponse
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [JsonArrayResponse]
    def jsonarray(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = jsonarray_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Run inference on the input and returns it as a JsonArrayResponse
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(JsonArrayResponse, Fixnum, Hash)>] JsonArrayResponse data, response status code and response headers
    def jsonarray_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.jsonarray ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.jsonarray"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.jsonarray"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.jsonarray"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.jsonarray"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/jsonarray'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'JsonArrayResponse')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#jsonarray\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Get logs file path
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [String]
    def logfilepath(deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = logfilepath_with_http_info(deployment_name, version_name, model_name, opts)
      data
    end

    # Get logs file path
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(String, Fixnum, Hash)>] String data, response status code and response headers
    def logfilepath_with_http_info(deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.logfilepath ...'
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.logfilepath"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.logfilepath"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.logfilepath"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/logfilepath'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['text'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:GET, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'String')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#logfilepath\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Get logs
    # @param body the the log request
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [LogBatch]
    def logs(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = logs_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Get logs
    # @param body the the log request
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(LogBatch, Fixnum, Hash)>] LogBatch data, response status code and response headers
    def logs_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.logs ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.logs"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.logs"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.logs"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.logs"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/logs'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'LogBatch')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#logs\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # this method can be used to get the meta data for the current model which set to the server
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [MetaData]
    def meta_get(deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = meta_get_with_http_info(deployment_name, version_name, model_name, opts)
      data
    end

    # this method can be used to get the meta data for the current model which set to the server
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(MetaData, Fixnum, Hash)>] MetaData data, response status code and response headers
    def meta_get_with_http_info(deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.meta_get ...'
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.meta_get"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.meta_get"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.meta_get"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/meta'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:GET, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'MetaData')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#meta_get\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # This method can be used to set meta data for the current model which is set to the server
    # @param body the meta data object
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [MetaData]
    def meta_post(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = meta_post_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # This method can be used to set meta data for the current model which is set to the server
    # @param body the meta data object
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(MetaData, Fixnum, Hash)>] MetaData data, response status code and response headers
    def meta_post_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.meta_post ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.meta_post"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.meta_post"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.meta_post"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.meta_post"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/meta'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'MetaData')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#meta_post\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Set the model to be served
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :file The model file to upload (.pb file)
    # @return [ModelStatus]
    def modelset(deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = modelset_with_http_info(deployment_name, version_name, model_name, opts)
      data
    end

    # Set the model to be served
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :file The model file to upload (.pb file)
    # @return [Array<(ModelStatus, Fixnum, Hash)>] ModelStatus data, response status code and response headers
    def modelset_with_http_info(deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.modelset ...'
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.modelset"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.modelset"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.modelset"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/modelset'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['file'] = opts[:'file'] if !opts[:'file'].nil?

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'ModelStatus')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#modelset\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Update the model to be served
    # @param file The model file to update with (.pb file)
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [ModelStatus]
    def modelupdate(file, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = modelupdate_with_http_info(file, deployment_name, version_name, model_name, opts)
      data
    end

    # Update the model to be served
    # @param file The model file to update with (.pb file)
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(ModelStatus, Fixnum, Hash)>] ModelStatus data, response status code and response headers
    def modelupdate_with_http_info(file, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.modelupdate ...'
      end
      # verify the required parameter 'file' is set
      if @api_client.config.client_side_validation && file.nil?
        fail ArgumentError, "Missing the required parameter 'file' when calling InferenceApi.modelupdate"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.modelupdate"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.modelupdate"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.modelupdate"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/modelupdate'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['file'] = file

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'ModelStatus')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#modelupdate\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Represents all of the labels for a given classification
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [MultiClassClassificationResult]
    def multiclassify(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = multiclassify_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Represents all of the labels for a given classification
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(MultiClassClassificationResult, Fixnum, Hash)>] MultiClassClassificationResult data, response status code and response headers
    def multiclassify_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.multiclassify ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.multiclassify"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.multiclassify"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.multiclassify"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.multiclassify"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/multiclassify'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'MultiClassClassificationResult')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#multiclassify\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Get the output from the network, based on the given INDArray[] input
    # Networks with multiple input/output are supported via this method. A Normalizer will be used if needsPreProcessing is set to true. The output/returned array of INDArray will be the raw predictions, and consequently this method can be used for classification or regression networks, with any type of output layer (standard, time series / RnnOutputLayer, etc).
    # @param body The multiple input arrays with mask inputs to run inferences on
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [MultiPredictResponse]
    def multipredict(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = multipredict_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Get the output from the network, based on the given INDArray[] input
    # Networks with multiple input/output are supported via this method. A Normalizer will be used if needsPreProcessing is set to true. The output/returned array of INDArray will be the raw predictions, and consequently this method can be used for classification or regression networks, with any type of output layer (standard, time series / RnnOutputLayer, etc).
    # @param body The multiple input arrays with mask inputs to run inferences on
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(MultiPredictResponse, Fixnum, Hash)>] MultiPredictResponse data, response status code and response headers
    def multipredict_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.multipredict ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.multipredict"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.multipredict"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.multipredict"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.multipredict"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/multipredict'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'MultiPredictResponse')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#multipredict\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Get the output from the network using the given image file using the /multipredict endpoint's method
    # Networks with multiple input/output are supported via this method. A Normalizer will be used if needsPreProcessing is set to true. The output/returned array of INDArray will be the raw predictions, and consequently this method can be used for classification or regression networks, with any type of output layer (standard, time series / RnnOutputLayer, etc).
    # @param file The image file to run the prediction on
    # @param id The id of the request (could be self generated)
    # @param needs_preprocessing Whether or not the preprocessing is required (either &#39;true&#39; or &#39;false&#39;)
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [MultiPredictResponse]
    def multipredictimage(file, id, needs_preprocessing, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = multipredictimage_with_http_info(file, id, needs_preprocessing, deployment_name, version_name, model_name, opts)
      data
    end

    # Get the output from the network using the given image file using the /multipredict endpoint&#39;s method
    # Networks with multiple input/output are supported via this method. A Normalizer will be used if needsPreProcessing is set to true. The output/returned array of INDArray will be the raw predictions, and consequently this method can be used for classification or regression networks, with any type of output layer (standard, time series / RnnOutputLayer, etc).
    # @param file The image file to run the prediction on
    # @param id The id of the request (could be self generated)
    # @param needs_preprocessing Whether or not the preprocessing is required (either &#39;true&#39; or &#39;false&#39;)
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(MultiPredictResponse, Fixnum, Hash)>] MultiPredictResponse data, response status code and response headers
    def multipredictimage_with_http_info(file, id, needs_preprocessing, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.multipredictimage ...'
      end
      # verify the required parameter 'file' is set
      if @api_client.config.client_side_validation && file.nil?
        fail ArgumentError, "Missing the required parameter 'file' when calling InferenceApi.multipredictimage"
      end
      # verify the required parameter 'id' is set
      if @api_client.config.client_side_validation && id.nil?
        fail ArgumentError, "Missing the required parameter 'id' when calling InferenceApi.multipredictimage"
      end
      # verify the required parameter 'needs_preprocessing' is set
      if @api_client.config.client_side_validation && needs_preprocessing.nil?
        fail ArgumentError, "Missing the required parameter 'needs_preprocessing' when calling InferenceApi.multipredictimage"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.multipredictimage"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.multipredictimage"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.multipredictimage"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/multipredictimage'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['file'] = file
      form_params['id'] = id
      form_params['needs_preprocessing'] = needs_preprocessing

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'MultiPredictResponse')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#multipredictimage\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Run inference on the input array.
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Prediction]
    def predict(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = predict_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Run inference on the input array.
    # @param body The input NDArray
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(Prediction, Fixnum, Hash)>] Prediction data, response status code and response headers
    def predict_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.predict ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.predict"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.predict"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.predict"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.predict"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/predict'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'Prediction')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#predict\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Run inference on the input array, using input image file from multipart form data.
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :image The file to upload.
    # @return [Prediction]
    def predictimage(deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = predictimage_with_http_info(deployment_name, version_name, model_name, opts)
      data
    end

    # Run inference on the input array, using input image file from multipart form data.
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @option opts [File] :image The file to upload.
    # @return [Array<(Prediction, Fixnum, Hash)>] Prediction data, response status code and response headers
    def predictimage_with_http_info(deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.predictimage ...'
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.predictimage"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.predictimage"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.predictimage"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/predictimage'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['multipart/form-data'])

      # form parameters
      form_params = {}
      form_params['image'] = opts[:'image'] if !opts[:'image'].nil?

      # http body (model)
      post_body = nil
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'Prediction')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#predictimage\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Preprocesses the input and run inference on it
    # @param body The input array
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Prediction]
    def predictwithpreprocess(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = predictwithpreprocess_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Preprocesses the input and run inference on it
    # @param body The input array
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(Prediction, Fixnum, Hash)>] Prediction data, response status code and response headers
    def predictwithpreprocess_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.predictwithpreprocess ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.predictwithpreprocess"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.predictwithpreprocess"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.predictwithpreprocess"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.predictwithpreprocess"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/predictwithpreprocess'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'Prediction')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#predictwithpreprocess\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
    # Preprocesses the input and run inference on it and returns it as a JsonArrayResponse
    # @param body The input array
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [JsonArrayResponse]
    def predictwithpreprocessjson(body, deployment_name, version_name, model_name, opts = {})
      data, _status_code, _headers = predictwithpreprocessjson_with_http_info(body, deployment_name, version_name, model_name, opts)
      data
    end

    # Preprocesses the input and run inference on it and returns it as a JsonArrayResponse
    # @param body The input array
    # @param deployment_name Name of the deployment group
    # @param version_name Version name of the endpoint. The default value is \&quot;default\&quot;
    # @param model_name ID or name of the deployed model
    # @param [Hash] opts the optional parameters
    # @return [Array<(JsonArrayResponse, Fixnum, Hash)>] JsonArrayResponse data, response status code and response headers
    def predictwithpreprocessjson_with_http_info(body, deployment_name, version_name, model_name, opts = {})
      if @api_client.config.debugging
        @api_client.config.logger.debug 'Calling API: InferenceApi.predictwithpreprocessjson ...'
      end
      # verify the required parameter 'body' is set
      if @api_client.config.client_side_validation && body.nil?
        fail ArgumentError, "Missing the required parameter 'body' when calling InferenceApi.predictwithpreprocessjson"
      end
      # verify the required parameter 'deployment_name' is set
      if @api_client.config.client_side_validation && deployment_name.nil?
        fail ArgumentError, "Missing the required parameter 'deployment_name' when calling InferenceApi.predictwithpreprocessjson"
      end
      # verify the required parameter 'version_name' is set
      if @api_client.config.client_side_validation && version_name.nil?
        fail ArgumentError, "Missing the required parameter 'version_name' when calling InferenceApi.predictwithpreprocessjson"
      end
      # verify the required parameter 'model_name' is set
      if @api_client.config.client_side_validation && model_name.nil?
        fail ArgumentError, "Missing the required parameter 'model_name' when calling InferenceApi.predictwithpreprocessjson"
      end
      # resource path
      local_var_path = '/endpoints/{deploymentName}/model/{modelName}/{versionName}/predictwithpreprocessjson'.sub('{' + 'deploymentName' + '}', deployment_name.to_s).sub('{' + 'versionName' + '}', version_name.to_s).sub('{' + 'modelName' + '}', model_name.to_s)

      # query parameters
      query_params = {}

      # header parameters
      header_params = {}
      # HTTP header 'Accept' (if needed)
      header_params['Accept'] = @api_client.select_header_accept(['application/json'])
      # HTTP header 'Content-Type'
      header_params['Content-Type'] = @api_client.select_header_content_type(['application/json'])

      # form parameters
      form_params = {}

      # http body (model)
      post_body = @api_client.object_to_http_body(body)
      auth_names = ['api_key']
      data, status_code, headers = @api_client.call_api(:POST, local_var_path,
        :header_params => header_params,
        :query_params => query_params,
        :form_params => form_params,
        :body => post_body,
        :auth_names => auth_names,
        :return_type => 'JsonArrayResponse')
      if @api_client.config.debugging
        @api_client.config.logger.debug "API called: InferenceApi#predictwithpreprocessjson\nData: #{data.inspect}\nStatus code: #{status_code}\nHeaders: #{headers}"
      end
      return data, status_code, headers
    end
  end
end
